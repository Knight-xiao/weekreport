
### 本周拟实现的任务（周一制定）
- 1.跑通黄老师提供的基于学习和无模型结合的算法（已实现），并学习算法原理
- 2.针对`myosuite`中的肌肉骨骼系统，将上述算法移植到该系统上，实现肌肉骨骼系统抓取物体放置到箱子中的任务
- 3.阅读文献`Preserving and Combining Knowledge in Robotic Lifelong Reinforcement Learning`，并参考其github项目学习其中怎么用神经网络处理长时序问题


#### 任务一
创建了base环境，能够运行并实现了reaching任务（虽然训练时间长），在50轮训练后成功率基本能达到100%。

#### 任务二
该肌肉骨骼系统较复杂，其控制量高达63个（24个关节，39个肌腱，如下图所示）
PS：官方文档中说肌肉骨骼模型由 29 块骨骼、23 个关节和 39 个肌肉肌腱单位组成，但在mujoco中打开模型发现总共是63个控制量，不是23+39=62个。
<img src="https://github.com/Knight-xiao/weekreport/blob/main/%E7%A0%94%E4%B8%80%E4%B8%8B/week1/fig1.png" alt="fig1" style="display: block; margin: auto;">

至于observation，定义了一个包含多个状态量的obs字典，选取了其中的**9**个作为系统的observation：
**hand_qpos(37), hand_qvel(38), obj_pos(3), goal_pos(3), pos_err(3), obj_rot(4), goal_rot(4), rot_err(4)**。使用env.observation_space.shape[0]得到obs维度为96。
<img src="https://github.com/Knight-xiao/weekreport/blob/main/%E7%A0%94%E4%B8%80%E4%B8%8B/week1/fig2.png" alt="fig2" style="display: block; margin: auto;">

最后的goal_dim就是7（位置+四元数）
这样就确定了肌肉骨骼系统的观察量和控制量：
**dim_x = 96 ; dim_u = 63 ; dim_g = 7**

奖励设置：要想实现grasp-place任务，奖励函数设置是一个重要项目
- 接近目标（Reach）：训练智能体最小化手掌与目标物体之间的距离。该阶段可进一步拆分，例如先最小化 x-y 方向的距离，并鼓励手指张开，然后再最小化 z 方向的距离。
- 抓取与移动（Grasp & Move）：训练智能体抓取物体并移动到目标位置。其中，z 方向目标初始设定比最终目标高 40 cm，同时 x-y 位置可设为初始物体位置或最终目标位置，以优化运动路径。
- 插入（Insert）：训练智能体完成物体插入任务，并最大化任务完成度。同时，保留一定权重的抓取阶段奖励，以持续鼓励智能体抓取复杂物体。



